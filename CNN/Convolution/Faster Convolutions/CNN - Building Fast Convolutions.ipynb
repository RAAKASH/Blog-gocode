{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast convolution tutorial\n",
    "This tutorial is about implementing fast convolutions using im2col trick.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    \"\"\"\n",
    "    Refer The below link to know why mutable datasetrutures cant be in the initialization\n",
    "    https://stackoverflow.com/questions/4841782/python-constructor-and-default-value\n",
    "    \"\"\"\n",
    "    def __init__(self,value,parent=None,child=None,operation=None,grad=None,gradstatus =0):\n",
    "        self.value = value\n",
    "        self.grad = grad\n",
    "        self.operation = operation\n",
    "        self.gradstatus = 0\n",
    "        if child is None:\n",
    "            self.child = []\n",
    "        else:\n",
    "            self.child = child\n",
    "        if parent is None:\n",
    "            self.parent = []\n",
    "        else:\n",
    "            self.parent = parent\n",
    "            \n",
    "        \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "    def get_consumer(self):\n",
    "        return self.child\n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "    def get_operation(self):\n",
    "        return self.operation\n",
    "    def get_grad(self):\n",
    "        return self.grad\n",
    "    def get_gradstatus(self):\n",
    "        return self.gradstatus\n",
    "    \n",
    "    def update_child(self,child):\n",
    "        self.child.append(child)\n",
    "    def update_value(self,value):\n",
    "        self.value = value\n",
    "    def update_grad(self,grad):\n",
    "        self.grad += grad\n",
    "   \n",
    "    def set_grad(self,grad):\n",
    "        self.grad = grad\n",
    "    def set_gradstatus(self,stat):\n",
    "        self.gradstatus = stat\n",
    "        \n",
    "    def size(self):\n",
    "        return 1\n",
    "    def __repr__(self):\n",
    "        return 'tensor object:'+ str(id(self)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# im2col made faster using 2d input and 2d output\n",
    "Before importing the below im2col, col2im.. files you have to compile them running the below code in command prompt.\n",
    ">python setup.py build_ext --inplace\n",
    "\n",
    "You can see each of the codes corresponding speed by using the below code\n",
    ">cython -a im2col_cython.pyx\n",
    "\n",
    ">cython -a col2im_cython.pyx\n",
    "\n",
    ">cython -a im2col6.pyx\n",
    "\n",
    "The above code will generate html files, the yellowness depicting the time consumption, more yellow more time consumed in operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import im2col6 #from cs231n\n",
    "import im2col_cython\n",
    "import col2im_cython\n",
    "\n",
    "class Convolution2D:\n",
    "    import numpy as np\n",
    "    def __init__(self,stride=2,pad=1):\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def __call__(self,X,w):\n",
    "        res = Convolution2D.__conv_v5_3d__(X,w,self.stride,self.pad)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "            \n",
    "    def __get_input_value__(input1,input2):\n",
    "        return (input1.get_value(),input2.get_value())\n",
    "    \n",
    "    def __pad__(X_val,pad):\n",
    "        x_shp = X_val.shape\n",
    "        X_tmp    = np.zeros((x_shp[0],x_shp[1],x_shp[2]+2*pad,x_shp[3]+2*pad))\n",
    "        X_tmp[:,:,pad:(x_shp[2]+pad),pad:(x_shp[3]+pad)] = X_val\n",
    "        return X_tmp\n",
    "        #return np.pad(X_val,((0,0),(0,0),(pad,pad),(pad,pad)),'constant',constant_values=0) #very slow\n",
    "    \n",
    "    def __get_shape__(X_val,w_val):\n",
    "        return (X_val.shape,w_val.shape)\n",
    "    \n",
    "    def __assert_shape__(x_shp,w_shp,stride):\n",
    "        try:\n",
    "            assert(x_shp[1]==w_shp[1]), 'Wrong channel,filter'\n",
    "            assert((x_shp[2]-w_shp[2])%stride == 0), 'Wrong stride'\n",
    "            assert((x_shp[3]-w_shp[3])%stride == 0), 'Wrong stride'\n",
    "            return (x_shp[0],w_shp[0],int((x_shp[2]-w_shp[2])/stride+1),int((x_shp[3]-w_shp[3])/stride+1))\n",
    "        except:\n",
    "            print('Error: Incompatible Tensor dimensions for convolution')\n",
    "            return 0\n",
    "\n",
    "    def __rect_shape__(X_val,w_val):\n",
    "        if(len(X_val.shape)==2):\n",
    "            X_val.reshape(1,1,X_val.shape)\n",
    "        if(len(w_val.shape)==3):\n",
    "            w_val.reshape(1,w_val.shape)\n",
    "        return X_val,w_val\n",
    "    \n",
    "    \"\"\"\n",
    "    # Naive implementatiom\n",
    "    def __conv_v1__(X,w,stride,pad):\n",
    "        X_val,w_val  = Convolution2D.__get_input_value__(X,w)\n",
    "        X_val        = Convolution2D.__pad__( X_val ,pad)\n",
    "        x_shp,w_shp  = Convolution2D.__get_shape__(X_val,w_val)\n",
    "        res_shape    = Convolution2D.__assert_shape__(x_shp,w_shp,stride)\n",
    "        X_res        = np.zeros(shape = res_shape)\n",
    "        if res_shape:\n",
    "\n",
    "            for i in range(res_shape[0]):\n",
    "                for j in range(res_shape[1]):\n",
    "\n",
    "                    row_idx = np.arange(i,x_shp[1]-w_shp[1]+i+1,stride)\n",
    "                    col_idx = np.arange(j,x_shp[2]-w_shp[2]+j+1,stride)\n",
    "                    X_res[i,j] = np.sum(np.multiply(X_val[:,i*stride:(i*stride+w_shp[1]),j*stride:(j*stride+w_shp[2])],w_val))\n",
    "\n",
    "\n",
    "            return X_res\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Smarter than above but still Naive\n",
    "    def __conv_v2__(X,w,stride,pad):\n",
    "        X_val,w_val  = Convolution2D.__get_input_value__(X,w)\n",
    "        X_val        = Convolution2D.__pad__( X_val ,pad)\n",
    "        x_shp,w_shp  = Convolution2D.__get_shape__(X_val,w_val)\n",
    "        res_shape    = Convolution2D. __assert_shape__(x_shp,w_shp,stride)\n",
    "        X_res        = np.zeros(shape = res_shape)\n",
    "        if res_shape:\n",
    "            for i in range(w_shp[1]):\n",
    "                for j in range(w_shp[2]):\n",
    "                    for l in range(w_shp[0]):\n",
    "                        row_idx = np.arange(i,x_shp[1]-w_shp[1]+i+1,stride)\n",
    "                        col_idx = np.arange(j,x_shp[2]-w_shp[2]+j+1,stride)\n",
    "                        X_res += X_val[l,row_idx[:, None], col_idx]*w_val[l,i,j] \n",
    "            return X_res\n",
    "    \"\"\"\n",
    "    \n",
    "    #\"\"\"\n",
    "    # Used for asserting answers obtained through vectorised implementation\n",
    "    def __conv_v2_3d__(X,w,stride,pad):\n",
    "        X_val,w_val  = Convolution2D.__get_input_value__(X,w)\n",
    "        X_val        = Convolution2D.__pad__( X_val ,pad)\n",
    "        x_shp,w_shp  = Convolution2D.__get_shape__(X_val,w_val)\n",
    "        res_shape    = Convolution2D. __assert_shape__(x_shp,w_shp,stride)\n",
    "        X_res        = np.zeros(shape = res_shape)\n",
    "        if res_shape:\n",
    "            for k in range(w_shp[0]):\n",
    "                for i in range(w_shp[2]):\n",
    "                    for j in range(w_shp[3]):\n",
    "                        for l in range(w_shp[1]):\n",
    "\n",
    "                            row_idx = np.arange(i,x_shp[2]-w_shp[2]+i+1,stride)\n",
    "                            col_idx = np.arange(j,x_shp[3]-w_shp[3]+j+1,stride)\n",
    "                            X_res[:,k,:,:] += X_val[:,l,row_idx[:, None], col_idx]*w_val[k,l,i,j] #0.19\n",
    "            return X_res\n",
    "    \n",
    "    def __back_conv_v2_3d__(X,w,stride,pad,grad):\n",
    "        X_val,w_val  = Convolution2D.__get_input_value__(X,w)\n",
    "        X_val        = Convolution2D.__pad__( X_val ,pad)\n",
    "        x_shp,w_shp  = Convolution2D.__get_shape__(X_val,w_val)\n",
    "        res_shape    = Convolution2D. __assert_shape__(x_shp,w_shp,stride)\n",
    "        X_rev        = np.zeros(shape = x_shp)\n",
    "        w_rev        = np.zeros(shape = w_shp)\n",
    "        if res_shape:\n",
    "            for k in range(w_shp[0]):\n",
    "                for i in range(w_shp[2]):\n",
    "                    for j in range(w_shp[3]):\n",
    "                        for l in range(w_shp[1]):\n",
    "                            row_idx = np.arange(i,x_shp[2]-w_shp[2]+i+1,stride)\n",
    "                            col_idx = np.arange(j,x_shp[3]-w_shp[3]+j+1,stride)\n",
    "                            w_rev[k,l,i,j] = np.sum(grad[:,k,:,:]*X_val[:,l,row_idx[:, None], col_idx])\n",
    "                            X_rev[:,l,row_idx[:, None], col_idx] += grad[:,k,:,:]*w_val[k,l,i,j]\n",
    "            return X_rev,w_rev\n",
    "    #\"\"\"\n",
    "   \n",
    "    def __conv_v5__(X,w,stride,pad):\n",
    "        X_val,w_val  = Convolution2D.__get_input_value__(X,w)\n",
    "        X_val        = Convolution2D.__pad__( X_val ,pad)\n",
    "        x_shp,w_shp  = Convolution2D.__get_shape__(X_val,w_val)\n",
    "        res_shp    = Convolution2D. __assert_shape__(x_shp,w_shp,stride)\n",
    "        X_res        = np.zeros(shape = (res_shp[0],res_shp[1],w_shp[1]*w_shp[2]*w_shp[0]))\n",
    "        if res_shp:\n",
    "            iter = -1\n",
    "            for l in range(w_shp[0]):   \n",
    "                for i in range(w_shp[1]):\n",
    "                    for j in range(w_shp[2]):\n",
    "                        iter+=1\n",
    "                        #print(iter)\n",
    "                        row_idx = np.arange(i,x_shp[1]-w_shp[1]+i+1,stride)\n",
    "                        col_idx = np.arange(j,x_shp[2]-w_shp[2]+j+1,stride)\n",
    "                        X_res[:,iter] = np.reshape(X_val[l,row_idx[:, None], col_idx],(res_shp[0]*res_shp[1]))\n",
    "            return np.reshape(np.dot(X_res,np.reshape(w_val,(w_shp[0]*w_shp[1]*w_shp[2],1))),(res_shp[0],res_shp[1]))\n",
    "    \n",
    "\n",
    "    def __conv_v5_3d__(X,w,stride,pad):\n",
    "        t0 = time.time()\n",
    "        X_val,w_val  = Convolution2D.__get_input_value__(X,w)\n",
    "        t1 = time.time()\n",
    "        print('Preliminary : getvalue ',t1-t0)\n",
    "        t0 = time.time()\n",
    "        X_val        = Convolution2D.__pad__( X_val ,pad)\n",
    "        t1 = time.time()\n",
    "        print('Preliminary : pad ',t1-t0)\n",
    "        t0 = time.time()\n",
    "        x_shp,w_shp  = Convolution2D.__get_shape__(X_val,w_val)\n",
    "        t1 = time.time()\n",
    "        print('Preliminary : getshape ',t1-t0)\n",
    "        t0 = time.time()\n",
    "        res_shp    = Convolution2D. __assert_shape__(x_shp,w_shp,stride)\n",
    "        t1 = time.time()\n",
    "        print('Preliminary : assert shape ',t1-t0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if res_shp:\n",
    "         \n",
    "            \n",
    "            \"\"\"\n",
    "            # CS231N im2col\n",
    "            t0 = time.time()\n",
    "            X_res = im2col6.im2col_cython(X_val,w_shp[2],w_shp[3], 0,stride)\n",
    "            t1 = time.time()\n",
    "            X_res = X_res.T\n",
    "            print('Cython way im2col:',t1-t0)\n",
    "            \n",
    "            t0 = time.time()\n",
    "            res=  np.dot(X_res,w_val.reshape(w_shp[0],w_shp[1]*w_shp[2]*w_shp[3]).T)\n",
    "            t1 = time.time()\n",
    "            print('Dot product:',t1-t0)\n",
    "            \n",
    "            t0 = time.time()\n",
    "            res = res.reshape(res_shp[2]*res_shp[3],x_shp[0],w_shp[0])\n",
    "            Res = res.swapaxes(0,1).swapaxes(1,2).reshape(res_shp)\n",
    "            t1 = time.time()\n",
    "            print('Final Swapping,reshaping:',t1-t0)\n",
    "            \"\"\"\n",
    "            #\"\"\"\n",
    "            # My code\n",
    "            t0 = time.time()\n",
    "            X_res = im2col_cython.im2col_2d(np.array(w_shp),np.array(x_shp),stride,X_val.reshape(x_shp[0]*x_shp[1]*x_shp[2],x_shp[3]))\n",
    "            \n",
    "            t1 = time.time()\n",
    "            print('Cython way im2col:',t1-t0)\n",
    "            \n",
    "            t0 = time.time()\n",
    "            res=  np.dot(X_res,w_val.reshape(w_shp[0],w_shp[1]*w_shp[2]*w_shp[3]).T)\n",
    "            t1 = time.time()\n",
    "            print('Dot product:',t1-t0)\n",
    "            \n",
    "            t0 = time.time()\n",
    "            res = res.reshape(x_shp[0],res_shp[2]*res_shp[3],w_shp[0])\n",
    "            Res = res.swapaxes(1,2).reshape(res_shp)\n",
    "            t1 = time.time()\n",
    "            print('Final Swapping,reshaping:',t1-t0)\n",
    "            #\"\"\"\n",
    "            \n",
    "            return Res\n",
    "        \n",
    "    def __back_conv_v5_3d__(X,w,stride,pad,grad):\n",
    "        \n",
    "        X_val,w_val  = Convolution2D.__get_input_value__(X,w)\n",
    "        X_val        = Convolution2D.__pad__( X_val ,pad)\n",
    "        x_shp,w_shp  = Convolution2D.__get_shape__(X_val,w_val)\n",
    "        res_shp    = Convolution2D. __assert_shape__(x_shp,w_shp,stride)\n",
    "        if res_shp:\n",
    "           \n",
    "            indices = np.arange(w_shp[1])*(w_shp[2]*w_shp[3])\n",
    "            \n",
    "            t0 = time.time()\n",
    "            X_res = im2col_cython.im2col_2d(np.array(w_shp),np.array(x_shp),stride,X_val.reshape(x_shp[0]*x_shp[1]*x_shp[2],x_shp[3]))\n",
    "            t1 = time.time()\n",
    "            print('Cython way im2col',t1-t0)\n",
    "            # 19600x2500\n",
    "            \n",
    "            t0 = time.time()\n",
    "            w_val_res = w_val.reshape(w_shp[0],w_shp[1]*w_shp[2]*w_shp[3])\n",
    "            t1 = time.time()\n",
    "            print('W_val reshape',t1-t0)\n",
    "            #25x2500\n",
    "            \n",
    "            t0 = time.time()\n",
    "            grad = grad.reshape(x_shp[0],w_shp[0],res_shp[2]*res_shp[3]).swapaxes(1,2).reshape(x_shp[0]*res_shp[2]*res_shp[3],w_shp[0])\n",
    "            t1 = time.time()\n",
    "            print('grad reshaping',t1-t0)\n",
    "            # 19600x25\n",
    "            \n",
    "            t0 = time.time()\n",
    "            w_grad = np.dot(grad.T,X_res)\n",
    "            t1 = time.time()\n",
    "            print('Dot for finding w_grad',t1-t0)\n",
    "            \n",
    "            \n",
    "            t0 = time.time()\n",
    "            x_grad = np.dot(grad, w_val_res)\n",
    "            t1 = time.time()\n",
    "            print('Dot prod for xgrad',t1-t0)\n",
    "            #19600x2500\n",
    "            \n",
    "            X_grad = np.zeros(x_shp)\n",
    "            \n",
    "            \n",
    "            t0 = time.time()\n",
    "            X_grad = col2im_cython.col2im(np.array(w_shp),np.array(x_shp),stride,x_grad)\n",
    "            t1 = time.time()\n",
    "            print('Cython way col2im',t1-t0)\n",
    "            #100*100*31x31\n",
    "            \n",
    "            \n",
    "            t0 = time.time()\n",
    "            X_grad= X_grad.reshape(x_shp)\n",
    "            w_grad = w_grad.reshape(w_shp)\n",
    "            t1 = time.time()\n",
    "            print('Final Reshaping',t1-t0)\n",
    "            \n",
    "      \n",
    "\n",
    "            return(X_grad,w_grad)\n",
    "      \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing speed difference between Naive and fast convolutions\n",
    "\n",
    "The fast convolutions were implemented by im2col_cython - my personal code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Optimized Forward_prop \n",
      "Preliminary : getvalue  0.0\n",
      "Preliminary : pad  0.008035421371459961\n",
      "Preliminary : getshape  0.0\n",
      "Preliminary : assert shape  0.0\n",
      "Cython way im2col: 0.029267072677612305\n",
      "Dot product: 0.031977176666259766\n",
      "Final Swapping,reshaping: 0.0\n",
      "Optimized Forward_prop total time:  0.07825160026550293\n",
      "\n",
      "Naive Forward_prop 1.3777029514312744\n",
      "\n",
      "Naive Back_prop total time 4.454310417175293 \n",
      "\n",
      "In Optimized Back_prop\n",
      "Cython way im2col 0.028493165969848633\n",
      "W_val reshape 0.0\n",
      "grad reshaping 0.0\n",
      "Dot for finding w_grad 0.019978761672973633\n",
      "Dot prod for xgrad 0.04398965835571289\n",
      "Cython way col2im 0.03198885917663574\n",
      "Final Reshaping 0.0\n",
      "Optimized Back_prop total time  0.14444375038146973\n"
     ]
    }
   ],
   "source": [
    "# Testing and benchmarking forwarprop and backprop of fast vs naive\n",
    "import numpy as np\n",
    "import time \n",
    "np.random.rand(1)\n",
    "xval = np.random.rand(100, 10, 31, 31)\n",
    "wval = np.random.rand(25, 10, 5,5)\n",
    "x1 = Tensor(xval)\n",
    "w1 = Tensor(wval)\n",
    "t0 = time.time()\n",
    "print('In Optimized Forward_prop ' )\n",
    "Res1 = Convolution2D.__conv_v5_3d__(x1,w1,stride=2,pad=0)\n",
    "t1 = time.time()\n",
    "print('Optimized Forward_prop total time: ',t1-t0 )\n",
    "#\"\"\"\n",
    "t0 = time.time()\n",
    "Res2 = Convolution2D.__conv_v2_3d__(x1,w1,stride=2,pad=0)\n",
    "t1 = time.time()\n",
    "print('\\nNaive Forward_prop',t1-t0 )\n",
    "#print(Res1 - Res2)\n",
    "assert(abs(Res1-Res2)<10**-8).all()\n",
    "#\"\"\"\n",
    "#\"\"\"\n",
    "t0 = time.time()\n",
    "bk1 = Convolution2D.__back_conv_v2_3d__(x1,w1,stride=2,pad=0,grad=Res1)\n",
    "\n",
    "t1 = time.time()\n",
    "print('\\nNaive Back_prop total time',t1-t0,'\\n' )\n",
    "#\"\"\"\n",
    "print('In Optimized Back_prop') \n",
    "t0 = time.time()\n",
    "bk2 = Convolution2D.__back_conv_v5_3d__(x1,w1,stride=2,pad=0,grad=Res1)\n",
    "t1 = time.time()\n",
    "print('Optimized Back_prop total time ',t1-t0) \n",
    "#\"\"\"\n",
    "assert(abs(bk2[0]-bk1[0])<10**-9).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing speed difference between Naive and fast convolutions\n",
    "\n",
    "The fast convolutions were implemented by im2col6 - CS231n code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Optimized Forward_prop \n",
      "Preliminary : getvalue  0.0\n",
      "Preliminary : pad  0.0025606155395507812\n",
      "Preliminary : getshape  0.0\n",
      "Preliminary : assert shape  0.0\n",
      "Cython way im2col: 0.055677175521850586\n",
      "Dot product: 0.03352022171020508\n",
      "Final Swapping,reshaping: 0.0\n",
      "Optimized Forward_prop total time:  0.09977841377258301\n",
      "\n",
      "Naive Forward_prop 1.380481481552124\n",
      "\n",
      "Naive Back_prop total time 4.1042468547821045 \n",
      "\n",
      "In Optimized Back_prop\n",
      "Cython way im2col 0.032623291015625\n",
      "W_val reshape 0.0\n",
      "grad reshaping 0.003998756408691406\n",
      "Dot for finding w_grad 0.016507387161254883\n",
      "Dot prod for xgrad 0.052613258361816406\n",
      "Cython way col2im 0.02958989143371582\n",
      "Final Reshaping 0.0\n",
      "Optimized Back_prop total time  0.15131187438964844\n"
     ]
    }
   ],
   "source": [
    "# Testing and benchmarking forwarprop and backprop of fast vs naive -CS231n code\n",
    "import numpy as np\n",
    "import time \n",
    "np.random.rand(1)\n",
    "xval = np.random.rand(100, 10, 31, 31)\n",
    "wval = np.random.rand(25, 10, 5,5)\n",
    "x1 = Tensor(xval)\n",
    "w1 = Tensor(wval)\n",
    "t0 = time.time()\n",
    "print('In Optimized Forward_prop ' )\n",
    "Res1 = Convolution2D.__conv_v5_3d__(x1,w1,stride=2,pad=0)\n",
    "t1 = time.time()\n",
    "print('Optimized Forward_prop total time: ',t1-t0 )\n",
    "#\"\"\"\n",
    "t0 = time.time()\n",
    "Res2 = Convolution2D.__conv_v2_3d__(x1,w1,stride=2,pad=0)\n",
    "t1 = time.time()\n",
    "print('\\nNaive Forward_prop',t1-t0 )\n",
    "#print(Res1 - Res2)\n",
    "assert(abs(Res1-Res2)<10**-8).all()\n",
    "#\"\"\"\n",
    "#\"\"\"\n",
    "t0 = time.time()\n",
    "bk1 = Convolution2D.__back_conv_v2_3d__(x1,w1,stride=2,pad=0,grad=Res1)\n",
    "\n",
    "t1 = time.time()\n",
    "print('\\nNaive Back_prop total time',t1-t0,'\\n' )\n",
    "#\"\"\"\n",
    "print('In Optimized Back_prop') \n",
    "t0 = time.time()\n",
    "bk2 = Convolution2D.__back_conv_v5_3d__(x1,w1,stride=2,pad=0,grad=Res1)\n",
    "t1 = time.time()\n",
    "print('Optimized Back_prop total time ',t1-t0) \n",
    "#\"\"\"\n",
    "assert(abs(bk2[0]-bk1[0])<10**-9).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Naive implementations are <b>15 to 20</b> times slower than fast imlementations.<br>\n",
    "Also fast implementaion using im2col_cython is faster than CS231n course code by <b>1.26 times</b>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
